{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "connTask is a package used for the prediction of task evoked patterns of activity (derived from tFMRI data) using functional connectivity data\n",
    "\n",
    "it is based on the work by Tavor et al (2016) https://science.sciencemag.org/content/352/6282/216\n",
    "\n",
    "install: \"pip install conntask_ni\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install conntask_ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1 3]\n",
      "[0 2 4]\n",
      "[['3' '4']\n",
      " ['7' '8']]\n",
      "1\n",
      "[0 2 4]\n",
      "[1 3]\n",
      "[['a' 'b']\n",
      " ['5' '6']\n",
      " ['9' '10']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "X = [('a','b'),(3,4),(5,6),(7,8),(9,10)]\n",
    "y = None\n",
    "groups = np.arange(len(X))\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "for fold, (train_indices, test_indices) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(fold)\n",
    "    print(train_indices)\n",
    "    print(test_indices)\n",
    "    print(np.array(X)[train_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.conntask_ni import utils, extract_features, model_and_predict\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torchio as tio\n",
    "import nilearn\n",
    "import nilearn.image \n",
    "import nilearn.masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.arange(2400).reshape(300,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_like_matlab_a(x):\n",
    "    # normalising like matlab. used for consistency with s.jbabdi's matlab code\n",
    "    dim = 0\n",
    "    dims = x.shape # (voxels, subj, num_features)\n",
    "    #print(dims) # (300, 4, 2)\n",
    "    dimsize = dims[dim] #voxels\n",
    "    dimrep = np.ones(len(dims), dtype=int) # (voxels, subj, num_features)\n",
    "    #print(dimrep) # [1 1 1]\n",
    "    dimrep[dim] = dimsize\n",
    "    #print(dimrep) # [300   1   1]\n",
    "    #print(x.shape) # (300, 4, 2)\n",
    "    x = x - np.tile(x.mean(axis=0), reps=dimrep)\n",
    "    #print(x.shape)\n",
    "    x = x/np.tile(x.std(axis=0, ddof=1), reps=dimrep)\n",
    "    #print(x)\n",
    "    x[np.isnan(x)] = 0\n",
    "    x[np.isinf(x)] = 0\n",
    "    x = x/np.sqrt(dimsize - 1)\n",
    "    #print(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.09966722, -0.09966722],\n",
       "        [-0.09966722, -0.09966722],\n",
       "        [-0.09966722, -0.09966722],\n",
       "        [-0.09966722, -0.09966722]],\n",
       "\n",
       "       [[-0.09900055, -0.09900055],\n",
       "        [-0.09900055, -0.09900055],\n",
       "        [-0.09900055, -0.09900055],\n",
       "        [-0.09900055, -0.09900055]],\n",
       "\n",
       "       [[-0.09833388, -0.09833388],\n",
       "        [-0.09833388, -0.09833388],\n",
       "        [-0.09833388, -0.09833388],\n",
       "        [-0.09833388, -0.09833388]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.09833388,  0.09833388],\n",
       "        [ 0.09833388,  0.09833388],\n",
       "        [ 0.09833388,  0.09833388],\n",
       "        [ 0.09833388,  0.09833388]],\n",
       "\n",
       "       [[ 0.09900055,  0.09900055],\n",
       "        [ 0.09900055,  0.09900055],\n",
       "        [ 0.09900055,  0.09900055],\n",
       "        [ 0.09900055,  0.09900055]],\n",
       "\n",
       "       [[ 0.09966722,  0.09966722],\n",
       "        [ 0.09966722,  0.09966722],\n",
       "        [ 0.09966722,  0.09966722],\n",
       "        [ 0.09966722,  0.09966722]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = normalise_like_matlab_a(sample)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451.96484375"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def normalise_like_matlab_b(x):\n",
    "    # normalising like matlab. used for consistency with s.jbabdi's matlab code\n",
    "    dim = 0\n",
    "    dims = x.shape # (voxels, subj, num_features)\n",
    "    dimsize = dims[dim] #voxels\n",
    "    x = (x - x.mean(axis=0)) /x.std(axis=0, ddof=1)\n",
    "    x[np.isnan(x)] = 0\n",
    "    x[np.isinf(x)] = 0   \n",
    "    x = x/np.sqrt(dimsize - 1)\n",
    "    return x\n",
    "psutil.Process().memory_info().rss / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type([1,2,3]) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= normalise_like_matlab_b(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190,\n",
       " 200,\n",
       " 210,\n",
       " 220,\n",
       " 230,\n",
       " 240,\n",
       " 250,\n",
       " 260,\n",
       " 270,\n",
       " 280,\n",
       " 290,\n",
       " 300,\n",
       " 310,\n",
       " 320,\n",
       " 330,\n",
       " 340,\n",
       " 350,\n",
       " 360,\n",
       " 370,\n",
       " 380,\n",
       " 390,\n",
       " 400,\n",
       " 410,\n",
       " 420,\n",
       " 430,\n",
       " 440,\n",
       " 450,\n",
       " 460,\n",
       " 470,\n",
       " 480,\n",
       " 490,\n",
       " 500,\n",
       " 510,\n",
       " 520,\n",
       " 530,\n",
       " 540,\n",
       " 550,\n",
       " 560,\n",
       " 570,\n",
       " 580,\n",
       " 590,\n",
       " 600,\n",
       " 610,\n",
       " 620,\n",
       " 630,\n",
       " 640,\n",
       " 650,\n",
       " 660,\n",
       " 670,\n",
       " 680,\n",
       " 690,\n",
       " 700,\n",
       " 710,\n",
       " 720,\n",
       " 730,\n",
       " 740,\n",
       " 750,\n",
       " 760,\n",
       " 770,\n",
       " 780,\n",
       " 790,\n",
       " 800,\n",
       " 810,\n",
       " 820,\n",
       " 830,\n",
       " 840,\n",
       " 850,\n",
       " 860,\n",
       " 870,\n",
       " 880,\n",
       " 890,\n",
       " 900,\n",
       " 910,\n",
       " 920,\n",
       " 930,\n",
       " 940,\n",
       " 950,\n",
       " 960,\n",
       " 970,\n",
       " 980,\n",
       " 990,\n",
       " 1000,\n",
       " 1010,\n",
       " 1020,\n",
       " 1030,\n",
       " 1040,\n",
       " 1050,\n",
       " 1060,\n",
       " 1070,\n",
       " 1080,\n",
       " 1090,\n",
       " 1100,\n",
       " 1110,\n",
       " 1120,\n",
       " 1130,\n",
       " 1140,\n",
       " 1150,\n",
       " 1160,\n",
       " 1170,\n",
       " 1180,\n",
       " 1190,\n",
       " 1200,\n",
       " 1210,\n",
       " 1220,\n",
       " 1230,\n",
       " 1240,\n",
       " 1250,\n",
       " 1260,\n",
       " 1270,\n",
       " 1280,\n",
       " 1290,\n",
       " 1300,\n",
       " 1310,\n",
       " 1320,\n",
       " 1330,\n",
       " 1340,\n",
       " 1350,\n",
       " 1360,\n",
       " 1370,\n",
       " 1380,\n",
       " 1390,\n",
       " 1400,\n",
       " 1410,\n",
       " 1420,\n",
       " 1430,\n",
       " 1440,\n",
       " 1450,\n",
       " 1460,\n",
       " 1470,\n",
       " 1480,\n",
       " 1490,\n",
       " 1500,\n",
       " 1510,\n",
       " 1520,\n",
       " 1530,\n",
       " 1540,\n",
       " 1550,\n",
       " 1560,\n",
       " 1570,\n",
       " 1580,\n",
       " 1590,\n",
       " 1600,\n",
       " 1610,\n",
       " 1620,\n",
       " 1630,\n",
       " 1640,\n",
       " 1650,\n",
       " 1660,\n",
       " 1670,\n",
       " 1680,\n",
       " 1690,\n",
       " 1700,\n",
       " 1710,\n",
       " 1720,\n",
       " 1730,\n",
       " 1740,\n",
       " 1750,\n",
       " 1760,\n",
       " 1770,\n",
       " 1780,\n",
       " 1790,\n",
       " 1800,\n",
       " 1810,\n",
       " 1820,\n",
       " 1830,\n",
       " 1840,\n",
       " 1850,\n",
       " 1860,\n",
       " 1870,\n",
       " 1880,\n",
       " 1890,\n",
       " 1900,\n",
       " 1910,\n",
       " 1920,\n",
       " 1930,\n",
       " 1940,\n",
       " 1950,\n",
       " 1960,\n",
       " 1970,\n",
       " 1980,\n",
       " 1990,\n",
       " 2000,\n",
       " 2010,\n",
       " 2020,\n",
       " 2030,\n",
       " 2040,\n",
       " 2050,\n",
       " 2060,\n",
       " 2070,\n",
       " 2080,\n",
       " 2090,\n",
       " 2100,\n",
       " 2110,\n",
       " 2120,\n",
       " 2130,\n",
       " 2140,\n",
       " 2150,\n",
       " 2160,\n",
       " 2170,\n",
       " 2180,\n",
       " 2190,\n",
       " 2200,\n",
       " 2210,\n",
       " 2220,\n",
       " 2230,\n",
       " 2240,\n",
       " 2250,\n",
       " 2260,\n",
       " 2270,\n",
       " 2280,\n",
       " 2290,\n",
       " 2300,\n",
       " 2310,\n",
       " 2320,\n",
       " 2330,\n",
       " 2340,\n",
       " 2350,\n",
       " 2360,\n",
       " 2370,\n",
       " 2380,\n",
       " 2390,\n",
       " 2400,\n",
       " 2410,\n",
       " 2420,\n",
       " 2430,\n",
       " 2440,\n",
       " 2450,\n",
       " 2460,\n",
       " 2470,\n",
       " 2480,\n",
       " 2490,\n",
       " 2500,\n",
       " 2510,\n",
       " 2520,\n",
       " 2530,\n",
       " 2540,\n",
       " 2550,\n",
       " 2560,\n",
       " 2570,\n",
       " 2580,\n",
       " 2590,\n",
       " 2600,\n",
       " 2610,\n",
       " 2620,\n",
       " 2630,\n",
       " 2640,\n",
       " 2650,\n",
       " 2660,\n",
       " 2670,\n",
       " 2680,\n",
       " 2690,\n",
       " 2700,\n",
       " 2710,\n",
       " 2720,\n",
       " 2730,\n",
       " 2740,\n",
       " 2750,\n",
       " 2760,\n",
       " 2770,\n",
       " 2780,\n",
       " 2790,\n",
       " 2800,\n",
       " 2810,\n",
       " 2820,\n",
       " 2830,\n",
       " 2840,\n",
       " 2850,\n",
       " 2860,\n",
       " 2870,\n",
       " 2880,\n",
       " 2890,\n",
       " 2900,\n",
       " 2910,\n",
       " 2920,\n",
       " 2930,\n",
       " 2940,\n",
       " 2950,\n",
       " 2960,\n",
       " 2970,\n",
       " 2980,\n",
       " 2990,\n",
       " 3000,\n",
       " 3010,\n",
       " 3020,\n",
       " 3030,\n",
       " 3040,\n",
       " 3050,\n",
       " 3060,\n",
       " 3070,\n",
       " 3080,\n",
       " 3090,\n",
       " 3100,\n",
       " 3110,\n",
       " 3120,\n",
       " 3130,\n",
       " 3140,\n",
       " 3150,\n",
       " 3160,\n",
       " 3170,\n",
       " 3180,\n",
       " 3190,\n",
       " 3200,\n",
       " 3210,\n",
       " 3220,\n",
       " 3230,\n",
       " 3240,\n",
       " 3250,\n",
       " 3260,\n",
       " 3270,\n",
       " 3280,\n",
       " 3290,\n",
       " 3300,\n",
       " 3310,\n",
       " 3320,\n",
       " 3330,\n",
       " 3340,\n",
       " 3350,\n",
       " 3360,\n",
       " 3370,\n",
       " 3380,\n",
       " 3390,\n",
       " 3400,\n",
       " 3410,\n",
       " 3420,\n",
       " 3430,\n",
       " 3440,\n",
       " 3450,\n",
       " 3460,\n",
       " 3470,\n",
       " 3480,\n",
       " 3490,\n",
       " 3500,\n",
       " 3510,\n",
       " 3520,\n",
       " 3530,\n",
       " 3540,\n",
       " 3550,\n",
       " 3560,\n",
       " 3570,\n",
       " 3580,\n",
       " 3590,\n",
       " 3600,\n",
       " 3610,\n",
       " 3620,\n",
       " 3630,\n",
       " 3640,\n",
       " 3650,\n",
       " 3660,\n",
       " 3670,\n",
       " 3680,\n",
       " 3690,\n",
       " 3700,\n",
       " 3710,\n",
       " 3720,\n",
       " 3730,\n",
       " 3740,\n",
       " 3750,\n",
       " 3760,\n",
       " 3770,\n",
       " 3780,\n",
       " 3790,\n",
       " 3800,\n",
       " 3810,\n",
       " 3820,\n",
       " 3830,\n",
       " 3840,\n",
       " 3850,\n",
       " 3860,\n",
       " 3870,\n",
       " 3880,\n",
       " 3890,\n",
       " 3900,\n",
       " 3910,\n",
       " 3920,\n",
       " 3930,\n",
       " 3940,\n",
       " 3950,\n",
       " 3960,\n",
       " 3970,\n",
       " 3980,\n",
       " 3990,\n",
       " 4000,\n",
       " 4010,\n",
       " 4020,\n",
       " 4030,\n",
       " 4040,\n",
       " 4050,\n",
       " 4060,\n",
       " 4070,\n",
       " 4080,\n",
       " 4090,\n",
       " 4100,\n",
       " 4110,\n",
       " 4120,\n",
       " 4130,\n",
       " 4140,\n",
       " 4150,\n",
       " 4160,\n",
       " 4170,\n",
       " 4180,\n",
       " 4190,\n",
       " 4200,\n",
       " 4210,\n",
       " 4220,\n",
       " 4230,\n",
       " 4240,\n",
       " 4250,\n",
       " 4260,\n",
       " 4270,\n",
       " 4280,\n",
       " 4290,\n",
       " 4300,\n",
       " 4310,\n",
       " 4320,\n",
       " 4330,\n",
       " 4340,\n",
       " 4350,\n",
       " 4360,\n",
       " 4370,\n",
       " 4380,\n",
       " 4390,\n",
       " 4400,\n",
       " 4410,\n",
       " 4420,\n",
       " 4430,\n",
       " 4440,\n",
       " 4450,\n",
       " 4460,\n",
       " 4470,\n",
       " 4480,\n",
       " 4490,\n",
       " 4500,\n",
       " 4510,\n",
       " 4520,\n",
       " 4530,\n",
       " 4540,\n",
       " 4550,\n",
       " 4560,\n",
       " 4570,\n",
       " 4580,\n",
       " 4590,\n",
       " 4600,\n",
       " 4610,\n",
       " 4620,\n",
       " 4630,\n",
       " 4640,\n",
       " 4650,\n",
       " 4660,\n",
       " 4670,\n",
       " 4680,\n",
       " 4690,\n",
       " 4700,\n",
       " 4710,\n",
       " 4720,\n",
       " 4730,\n",
       " 4740,\n",
       " 4750,\n",
       " 4760,\n",
       " 4770,\n",
       " 4780,\n",
       " 4790,\n",
       " 4800,\n",
       " 4810,\n",
       " 4820,\n",
       " 4830,\n",
       " 4840,\n",
       " 4850,\n",
       " 4860,\n",
       " 4870,\n",
       " 4880,\n",
       " 4890,\n",
       " 4900,\n",
       " 4910,\n",
       " 4920,\n",
       " 4930,\n",
       " 4940,\n",
       " 4950,\n",
       " 4960,\n",
       " 4970,\n",
       " 4980,\n",
       " 4990,\n",
       " 5000,\n",
       " 5010,\n",
       " 5020,\n",
       " 5030,\n",
       " 5040,\n",
       " 5050,\n",
       " 5060,\n",
       " 5070,\n",
       " 5080,\n",
       " 5090,\n",
       " 5100,\n",
       " 5110,\n",
       " 5120,\n",
       " 5130,\n",
       " 5140,\n",
       " 5150,\n",
       " 5160,\n",
       " 5170,\n",
       " 5180,\n",
       " 5190,\n",
       " 5200,\n",
       " 5210,\n",
       " 5220,\n",
       " 5230,\n",
       " 5240,\n",
       " 5250,\n",
       " 5260,\n",
       " 5270,\n",
       " 5280,\n",
       " 5290,\n",
       " 5300,\n",
       " 5310,\n",
       " 5320,\n",
       " 5330,\n",
       " 5340,\n",
       " 5350,\n",
       " 5360,\n",
       " 5370,\n",
       " 5380,\n",
       " 5390,\n",
       " 5400,\n",
       " 5410,\n",
       " 5420,\n",
       " 5430,\n",
       " 5440,\n",
       " 5450,\n",
       " 5460,\n",
       " 5470,\n",
       " 5480,\n",
       " 5490,\n",
       " 5500,\n",
       " 5510,\n",
       " 5520,\n",
       " 5530,\n",
       " 5540,\n",
       " 5550,\n",
       " 5560,\n",
       " 5570,\n",
       " 5580,\n",
       " 5590,\n",
       " 5600,\n",
       " 5610,\n",
       " 5620,\n",
       " 5630,\n",
       " 5640,\n",
       " 5650,\n",
       " 5660,\n",
       " 5670,\n",
       " 5680,\n",
       " 5690,\n",
       " 5700,\n",
       " 5710,\n",
       " 5720,\n",
       " 5730,\n",
       " 5740,\n",
       " 5750,\n",
       " 5760,\n",
       " 5770,\n",
       " 5780,\n",
       " 5790,\n",
       " 5800,\n",
       " 5810,\n",
       " 5820,\n",
       " 5830,\n",
       " 5840,\n",
       " 5850,\n",
       " 5860,\n",
       " 5870,\n",
       " 5880,\n",
       " 5890,\n",
       " 5900,\n",
       " 5910,\n",
       " 5920,\n",
       " 5930,\n",
       " 5940,\n",
       " 5950,\n",
       " 5960,\n",
       " 5970,\n",
       " 5980,\n",
       " 5990,\n",
       " 6000,\n",
       " 6010,\n",
       " 6020,\n",
       " 6030,\n",
       " 6040,\n",
       " 6050,\n",
       " 6060,\n",
       " 6070,\n",
       " 6080,\n",
       " 6090,\n",
       " 6100,\n",
       " 6110,\n",
       " 6120,\n",
       " 6130,\n",
       " 6140,\n",
       " 6150,\n",
       " 6160,\n",
       " 6170,\n",
       " 6180,\n",
       " 6190,\n",
       " 6200,\n",
       " 6210,\n",
       " 6220,\n",
       " 6230,\n",
       " 6240,\n",
       " 6250,\n",
       " 6260,\n",
       " 6270,\n",
       " 6280,\n",
       " 6290,\n",
       " 6300,\n",
       " 6310,\n",
       " 6320,\n",
       " 6330,\n",
       " 6340,\n",
       " 6350,\n",
       " 6360,\n",
       " 6370,\n",
       " 6380,\n",
       " 6390,\n",
       " 6400,\n",
       " 6410,\n",
       " 6420,\n",
       " 6430,\n",
       " 6440,\n",
       " 6450,\n",
       " 6460,\n",
       " 6470,\n",
       " 6480,\n",
       " 6490,\n",
       " 6500,\n",
       " 6510,\n",
       " 6520,\n",
       " 6530,\n",
       " 6540,\n",
       " 6550,\n",
       " 6560,\n",
       " 6570,\n",
       " 6580,\n",
       " 6590,\n",
       " 6600,\n",
       " 6610,\n",
       " 6620,\n",
       " 6630,\n",
       " 6640,\n",
       " 6650,\n",
       " 6660,\n",
       " 6670,\n",
       " 6680,\n",
       " 6690,\n",
       " 6700,\n",
       " 6710,\n",
       " 6720,\n",
       " 6730,\n",
       " 6740,\n",
       " 6750,\n",
       " 6760,\n",
       " 6770,\n",
       " 6780,\n",
       " 6790,\n",
       " 6800,\n",
       " 6810,\n",
       " 6820,\n",
       " 6830,\n",
       " 6840,\n",
       " 6850,\n",
       " 6860,\n",
       " 6870,\n",
       " 6880,\n",
       " 6890,\n",
       " 6900,\n",
       " 6910,\n",
       " 6920,\n",
       " 6930,\n",
       " 6940,\n",
       " 6950,\n",
       " 6960,\n",
       " 6970,\n",
       " 6980,\n",
       " 6990,\n",
       " 7000,\n",
       " 7010,\n",
       " 7020,\n",
       " 7030,\n",
       " 7040,\n",
       " 7050,\n",
       " 7060,\n",
       " 7070,\n",
       " 7080,\n",
       " 7090,\n",
       " 7100,\n",
       " 7110,\n",
       " 7120,\n",
       " 7130,\n",
       " 7140,\n",
       " 7150,\n",
       " 7160,\n",
       " 7170,\n",
       " 7180,\n",
       " 7190,\n",
       " 7200,\n",
       " 7210,\n",
       " 7220,\n",
       " 7230,\n",
       " 7240,\n",
       " 7250,\n",
       " 7260,\n",
       " 7270,\n",
       " 7280,\n",
       " 7290,\n",
       " 7300,\n",
       " 7310,\n",
       " 7320,\n",
       " 7330,\n",
       " 7340,\n",
       " 7350,\n",
       " 7360,\n",
       " 7370,\n",
       " 7380,\n",
       " 7390,\n",
       " 7400,\n",
       " 7410,\n",
       " 7420,\n",
       " 7430,\n",
       " 7440,\n",
       " 7450,\n",
       " 7460,\n",
       " 7470,\n",
       " 7480,\n",
       " 7490,\n",
       " 7500,\n",
       " 7510,\n",
       " 7520,\n",
       " 7530,\n",
       " 7540,\n",
       " 7550,\n",
       " 7560,\n",
       " 7570,\n",
       " 7580,\n",
       " 7590,\n",
       " 7600,\n",
       " 7610,\n",
       " 7620,\n",
       " 7630,\n",
       " 7640,\n",
       " 7650,\n",
       " 7660,\n",
       " 7670,\n",
       " 7680,\n",
       " 7690,\n",
       " 7700,\n",
       " 7710,\n",
       " 7720,\n",
       " 7730,\n",
       " 7740,\n",
       " 7750,\n",
       " 7760,\n",
       " 7770,\n",
       " 7780,\n",
       " 7790,\n",
       " 7800,\n",
       " 7810,\n",
       " 7820,\n",
       " 7830,\n",
       " 7840,\n",
       " 7850,\n",
       " 7860,\n",
       " 7870,\n",
       " 7880,\n",
       " 7890,\n",
       " 7900,\n",
       " 7910,\n",
       " 7920,\n",
       " 7930,\n",
       " 7940,\n",
       " 7950,\n",
       " 7960,\n",
       " 7970,\n",
       " 7980,\n",
       " 7990,\n",
       " 8000,\n",
       " 8010,\n",
       " 8020,\n",
       " 8030,\n",
       " 8040,\n",
       " 8050,\n",
       " 8060,\n",
       " 8070,\n",
       " 8080,\n",
       " 8090,\n",
       " 8100,\n",
       " 8110,\n",
       " 8120,\n",
       " 8130,\n",
       " 8140,\n",
       " 8150,\n",
       " 8160,\n",
       " 8170,\n",
       " 8180,\n",
       " 8190,\n",
       " 8200,\n",
       " 8210,\n",
       " 8220,\n",
       " 8230,\n",
       " 8240,\n",
       " 8250,\n",
       " 8260,\n",
       " 8270,\n",
       " 8280,\n",
       " 8290,\n",
       " 8300,\n",
       " 8310,\n",
       " 8320,\n",
       " 8330,\n",
       " 8340,\n",
       " 8350,\n",
       " 8360,\n",
       " 8370,\n",
       " 8380,\n",
       " 8390,\n",
       " 8400,\n",
       " 8410,\n",
       " 8420,\n",
       " 8430,\n",
       " 8440,\n",
       " 8450,\n",
       " 8460,\n",
       " 8470,\n",
       " 8480,\n",
       " 8490,\n",
       " 8500,\n",
       " 8510,\n",
       " 8520,\n",
       " 8530,\n",
       " 8540,\n",
       " 8550,\n",
       " 8560,\n",
       " 8570,\n",
       " 8580,\n",
       " 8590,\n",
       " 8600,\n",
       " 8610,\n",
       " 8620,\n",
       " 8630,\n",
       " 8640,\n",
       " 8650,\n",
       " 8660,\n",
       " 8670,\n",
       " 8680,\n",
       " 8690,\n",
       " 8700,\n",
       " 8710,\n",
       " 8720,\n",
       " 8730,\n",
       " 8740,\n",
       " 8750,\n",
       " 8760,\n",
       " 8770,\n",
       " 8780,\n",
       " 8790,\n",
       " 8800,\n",
       " 8810,\n",
       " 8820,\n",
       " 8830,\n",
       " 8840,\n",
       " 8850,\n",
       " 8860,\n",
       " 8870,\n",
       " 8880,\n",
       " 8890,\n",
       " 8900,\n",
       " 8910,\n",
       " 8920,\n",
       " 8930,\n",
       " 8940,\n",
       " 8950,\n",
       " 8960,\n",
       " 8970,\n",
       " 8980,\n",
       " 8990,\n",
       " 9000,\n",
       " 9010,\n",
       " 9020,\n",
       " 9030,\n",
       " 9040,\n",
       " 9050,\n",
       " 9060,\n",
       " 9070,\n",
       " 9080,\n",
       " 9090,\n",
       " 9100,\n",
       " 9110,\n",
       " 9120,\n",
       " 9130,\n",
       " 9140,\n",
       " 9150,\n",
       " 9160,\n",
       " 9170,\n",
       " 9180,\n",
       " 9190,\n",
       " 9200,\n",
       " 9210,\n",
       " 9220,\n",
       " 9230,\n",
       " 9240,\n",
       " 9250,\n",
       " 9260,\n",
       " 9270,\n",
       " 9280,\n",
       " 9290,\n",
       " 9300,\n",
       " 9310,\n",
       " 9320]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,9323,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first step is to extract functional connectivity features from the raw data (usually rsfMRI, couls be also naturalistic-stimuli fMRI or even tFMRI time-series data)\n",
    "\n",
    "to do so, we use a set of spatially individual components, derived from a group ica procedure, to define define a set of networks that will be the basis of our feature set.\n",
    "\n",
    "in this example, we use a set of 43 components dervied from the data of 100 HCP participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group ICA map given by the author (HCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifti_orig = nb.load('src/conntask_ni/files/ica_both_hemis_45_comp_cleaned.dtseries.nii') # i keep t\n",
    "ica = np.asarray(cifti_orig.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 91282)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica.shape # should be number of components * voxels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are trying to make group ica file of UKB as this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out bad components in GroupICA map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### component 25 (->21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91, 109, 91, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifti_orig = nb.load('/global/cfs/cdirs/m4244/junbeom/UKBiobank_BrainImaging_GroupMeanTemplates/rfMRI_ICA_d25.nii.gz')\n",
    "\n",
    "file = open('/global/cfs/cdirs/m4244/junbeom/UKBiobank_BrainImaging_GroupMeanTemplates/rfMRI_GoodComponents_d25_v1.txt','r')\n",
    "goodcomponent25 = [ int(i)-1 for i in file.readline().strip().split()]\n",
    "print(goodcomponent25)\n",
    "file.close()\n",
    "\n",
    "ica_good_21 = nilearn.image.index_img(nifti_orig, goodcomponent25)\n",
    "ica_good_21.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### component 100 (-> 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 51, 52, 56, 57, 59, 62, 63, 92]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(91, 109, 91, 55)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifti_orig = nb.load('/global/cfs/cdirs/m4244/junbeom/UKBiobank_BrainImaging_GroupMeanTemplates/rfMRI_ICA_d100.nii.gz')\n",
    "ica100 = np.asarray(nifti_orig.get_fdata())\n",
    "\n",
    "file = open('/global/cfs/cdirs/m4244/junbeom/UKBiobank_BrainImaging_GroupMeanTemplates/rfMRI_GoodComponents_d100_v1.txt','r')\n",
    "goodcomponent100 = [ int(i)-1 for i in file.readline().strip().split()] # -1 because this file starts from 1, but index starts from 0\n",
    "print(goodcomponent100)\n",
    "file.close()\n",
    "\n",
    "ica_good_55 = nilearn.image.index_img(nifti_orig, goodcomponent100) # filter out 45 bad group ica components\n",
    "ica_good_55.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, we go over all participants in our data set and perform the 2 steps of the feature extraction procedure:\n",
    "\n",
    "1) dual regression of group ica components, to yield participant-specific representation of the group-ica\n",
    "\n",
    "2) a weighted seed2voxel procedure on the the components from the previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking group ICA map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load ICBM 152 nonlin symmetric 6th generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 229, 193)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_file_nifti = nb.load('/global/cfs/cdirs/m4244/registration/icbm_avg_152_t1_tal_nlin_symmetric_VI_mask.nii')\n",
    "mask_file=mask_file_nifti.get_fdata().astype(int)\n",
    "mask_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_affine = nifti_orig.affine\n",
    "target_shape = nifti_orig.shape[:3]\n",
    "MNI152_mask = nilearn.image.resample_img(mask_file_nifti,target_affine=target_affine,target_shape=target_shape,interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91, 109, 91),\n",
       " array([[  -2.,    0.,    0.,   90.],\n",
       "        [   0.,    2.,    0., -126.],\n",
       "        [   0.,    0.,    2.,  -72.],\n",
       "        [   0.,    0.,    0.,    1.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNI152_mask.shape, MNI152_mask.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MNI152_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nb\u001b[38;5;241m.\u001b[39msave(\u001b[43mMNI152_mask\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNI_152_mask.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MNI152_mask' is not defined"
     ]
    }
   ],
   "source": [
    "nb.save(MNI152_mask,'MNI_152_mask.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessed MNI152 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb\n",
    "MNI152_mask = nb.load('output/UKB/mask/MNI_152_mask.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_affine = MNI152_mask.affine\n",
    "target_shape = MNI152_mask.shape[:3]\n",
    "\n",
    "ICBM152_graymatter = nilearn.image.resample_img(nilearn.datasets.fetch_icbm152_brain_gm_mask(),target_affine=target_affine,target_shape=target_shape,interpolation='nearest')\n",
    "nb.save(ICBM152_graymatter,'output/UKB/mask/ICBM_152_GM_mask.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_raw = nilearn.datasets.load_mni152_wm_mask()\n",
    "wm_raw.get_fdata().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(.get_fdata().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ICBM152_graymatter.get_fdata().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(nb.load(nilearn.datasets.fetch_icbm152_2009()['wm']).get_fdata().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nilearn.datasets' has no attribute 'fetch_icbm152_brain_wm_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m target_affine \u001b[38;5;241m=\u001b[39m MNI152_mask\u001b[38;5;241m.\u001b[39maffine\n\u001b[1;32m      2\u001b[0m target_shape \u001b[38;5;241m=\u001b[39m MNI152_mask\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m ICBM152_wm \u001b[38;5;241m=\u001b[39m nilearn\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresample_img(\u001b[43mnilearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_icbm152_brain_wm_mask\u001b[49m(),target_affine\u001b[38;5;241m=\u001b[39mtarget_affine,target_shape\u001b[38;5;241m=\u001b[39mtarget_shape,interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m nb\u001b[38;5;241m.\u001b[39msave(ICBM152_wm,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/UKB/mask/MNI_152_WM_mask.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nilearn.datasets' has no attribute 'fetch_icbm152_brain_wm_mask'"
     ]
    }
   ],
   "source": [
    "target_affine = MNI152_mask.affine\n",
    "target_shape = MNI152_mask.shape[:3]\n",
    "\n",
    "ICBM152_wm = nilearn.image.resample_img(nilearn.datasets.fetch_icbm152_2009()['wm'],target_affine=target_affine,target_shape=target_shape,interpolation='nearest')\n",
    "#nb.save(ICBM152_wm,'output/UKB/mask/MNI_152_WM_mask.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add dimension to add channel\n",
    "# mask_file = mask_file[np.newaxis,:,:,:]\n",
    "\n",
    "# # resize from (193,229,193) to (91,109,91)\n",
    "# resize_tio = tio.transforms.Resize((91,109,91),image_interpolation='nearest')\n",
    "# MNI152_mask_tio = resize_tio(mask_file)\n",
    "\n",
    "# # remove channel\n",
    "# MNI152_mask_tio = np.squeeze(MNI152_mask_tio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 109, 91, 21)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica_good_21.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 237969)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pixels = nilearn.masking.apply_mask(ica_good_21, mask_img=MNI152_mask)\n",
    "masked_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('UKB_groupica_21_comp_masked.npy',masked_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 109, 91, 55)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ica_good_55.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 237969)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pixels = nilearn.masking.apply_mask(ica_good_55, mask_img=MNI152_mask)\n",
    "masked_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('UKB_groupica_55_comp_masked.npy',masked_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load sample rsfMRI in MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = nb.load('/global/cfs/cdirs/m4244/registration/20227_1_MNI/1000246_20227_2_0_rsfMRI_MNI_space.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91, 109, 91, 490),\n",
       " array([[  -2.,    0.,    0.,   90.],\n",
       "        [   0.,    2.,    0., -126.],\n",
       "        [   0.,    0.,    2.,  -72.],\n",
       "        [   0.,    0.,    0.,    1.]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape, sample.affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 237969)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_pixels = nilearn.masking.apply_mask(sample, mask_img=MNI152_mask)\n",
    "masked_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_pixels_tio = sample.get_fdata()[MNI152_mask_tio == 1].swapaxes(0,1)\n",
    "# masked_pixels_tio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check whether mask file and registered rs-fMRI image matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcbf80e2c3544099d69ea0531ed470c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='x', max=90), IntSlider(value=54, description='y', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_3d_image(x, y, z)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import itk              # 2D 및 3D 이미지 시각화 라이브러리\n",
    "import itkwidgets\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "\n",
    "def explore_3d_image(x, y, z):\n",
    "    #plt.figure(figsize=(8,10))\n",
    "    # plt.title('Explore Layers of MRI', fontsize=18)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(8, 12))\n",
    "    \n",
    "    axes[0].imshow(MNI152_mask.get_fdata()[x, :, :], cmap='gist_heat')\n",
    "    axes[0].imshow(sample.get_fdata()[ x, :, :,0], cmap='gray',alpha=0.4)\n",
    "    axes[1].imshow(MNI152_mask.get_fdata()[:, y, :], cmap='gist_heat')\n",
    "    axes[1].imshow(sample.get_fdata()[:, y, :,0], cmap='gray',alpha=0.4)\n",
    "    axes[2].imshow(MNI152_mask.get_fdata()[:, :, z], cmap='gist_heat')\n",
    "    axes[2].imshow(sample.get_fdata()[ :, :, z,0], cmap='gray',alpha=0.4)\n",
    "    \n",
    "    #plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #return layer\n",
    " \n",
    "# Run the ipywidgets interact() function to explore the data\n",
    "interact(explore_3d_image, x=(0, MNI152_mask.shape[0]-1),y=(0, MNI152_mask.shape[1]-1),z=(0, MNI152_mask.shape[2]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchio (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e4602ebf044b7fa453cc2173fca823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='x', max=90), IntSlider(value=54, description='y', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_3d_image(x, y, z)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "# import os\n",
    "# import json\n",
    "# import numpy as np\n",
    "# from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# import torchvision\n",
    "# from torchvision import models\n",
    "# from torchvision import transforms\n",
    "\n",
    "# from captum.attr import IntegratedGradients\n",
    "# from captum.attr import GradientShap\n",
    "# from captum.attr import Occlusion\n",
    "# from captum.attr import NoiseTunnel\n",
    "# from captum.attr import visualization as viz\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import LogNorm\n",
    "# import itk              # 2D 및 3D 이미지 시각화 라이브러리\n",
    "# import itkwidgets\n",
    "# from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "\n",
    "# def explore_3d_image(x, y, z):\n",
    "#     #plt.figure(figsize=(8,10))\n",
    "#     # plt.title('Explore Layers of MRI', fontsize=18)\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(8, 12))\n",
    "    \n",
    "#     axes[0].imshow(MNI152_mask_tio[x, :, :], cmap='gist_heat')\n",
    "#     axes[0].imshow(sample.get_fdata()[ x, :, :,0], cmap='gray',alpha=0.4)\n",
    "#     axes[1].imshow(MNI152_mask_tio[:, y, :], cmap='gist_heat')\n",
    "#     axes[1].imshow(sample.get_fdata()[:, y, :,0], cmap='gray',alpha=0.4)\n",
    "#     axes[2].imshow(MNI152_mask_tio[:, :, z], cmap='gist_heat')\n",
    "#     axes[2].imshow(sample.get_fdata()[ :, :, z,0], cmap='gray',alpha=0.4)\n",
    "    \n",
    "#     #plt.axis('off')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     #return layer\n",
    " \n",
    "# # Run the ipywidgets interact() function to explore the data\n",
    "# interact(explore_3d_image, x=(0, MNI152_mask.shape[0]-1),y=(0, MNI152_mask.shape[1]-1),z=(0, MNI152_mask.shape[2]-1))\n",
    "\n",
    "#should not use this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check whether mask file and AAL Templete image matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 91282)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.load('src/conntask_ni/files/Schaefer2018_100Parcels_7Networks_order.dtseries.nii').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 13.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 16.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 22.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 29.0,\n",
       " 30.0,\n",
       " 31.0,\n",
       " 32.0,\n",
       " 33.0,\n",
       " 34.0,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 37.0,\n",
       " 38.0,\n",
       " 39.0,\n",
       " 40.0,\n",
       " 41.0,\n",
       " 42.0,\n",
       " 43.0,\n",
       " 44.0,\n",
       " 45.0,\n",
       " 46.0,\n",
       " 47.0,\n",
       " 48.0,\n",
       " 49.0,\n",
       " 50.0,\n",
       " 51.0,\n",
       " 52.0,\n",
       " 53.0,\n",
       " 54.0,\n",
       " 55.0,\n",
       " 56.0,\n",
       " 57.0,\n",
       " 58.0,\n",
       " 59.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 62.0,\n",
       " 63.0,\n",
       " 64.0,\n",
       " 65.0,\n",
       " 66.0,\n",
       " 67.0,\n",
       " 68.0,\n",
       " 69.0,\n",
       " 70.0,\n",
       " 71.0,\n",
       " 72.0,\n",
       " 73.0,\n",
       " 74.0,\n",
       " 75.0,\n",
       " 76.0,\n",
       " 77.0,\n",
       " 78.0,\n",
       " 79.0,\n",
       " 80.0,\n",
       " 81.0,\n",
       " 82.0,\n",
       " 83.0,\n",
       " 84.0,\n",
       " 85.0,\n",
       " 86.0,\n",
       " 87.0,\n",
       " 88.0,\n",
       " 89.0,\n",
       " 90.0,\n",
       " 91.0,\n",
       " 92.0,\n",
       " 93.0,\n",
       " 94.0,\n",
       " 95.0,\n",
       " 96.0,\n",
       " 97.0,\n",
       " 98.0,\n",
       " 99.0,\n",
       " 100.0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(np.squeeze(nb.load('src/conntask_ni/files/Schaefer2018_100Parcels_7Networks_order.dtseries.nii').get_fdata()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schaefer2018_100Parcels_7Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn.masking\n",
    "ROI_Sch_100P_7N = nb.load('Schaefer2018_ROIs/Schaefer2018_100Parcels_7Networks_order_FSLMNI152_2mm.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_ROI_Sch_100P_7N = nilearn.masking.apply_mask(ROI_Sch_100P_7N, mask_img=MNI152_mask)\n",
    "np.save('masked_ROI_Sch_100P_7N.npy',masked_ROI_Sch_100P_7N[np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 237969)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('result/UKB/features-d21/1000246_20227_2_0_features_21_comps.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60da3462d32d41b5b624fc6e2032edf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='x', max=90), IntSlider(value=54, description='y', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_3d_image(x, y, z)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import itk              # 2D 및 3D 이미지 시각화 라이브러리\n",
    "import itkwidgets\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "\n",
    "def explore_3d_image(x, y, z):\n",
    "    #plt.figure(figsize=(8,10))\n",
    "    # plt.title('Explore Layers of MRI', fontsize=18)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(8, 12))\n",
    "    \n",
    "    axes[0].imshow(MNI152_mask.get_fdata()[x, :, :], cmap='gray',alpha=0.4)\n",
    "    axes[0].imshow(ROI_Sch_100P_7N.get_fdata()[ x, :, :], cmap='gist_heat',alpha=0.7)\n",
    "    axes[1].imshow(MNI152_mask.get_fdata()[:, y, :], cmap='gray',alpha=0.4)\n",
    "    axes[1].imshow(ROI_Sch_100P_7N.get_fdata()[:, y, :], cmap='gist_heat',alpha=0.7)\n",
    "    axes[2].imshow(MNI152_mask.get_fdata()[:, :, z], cmap='gray',alpha=0.4)\n",
    "    axes[2].imshow(ROI_Sch_100P_7N.get_fdata()[ :, :, z], cmap='gist_heat',alpha=0.7)\n",
    "    \n",
    "    #plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #return layer\n",
    " \n",
    "# Run the ipywidgets interact() function to explore the data\n",
    "interact(explore_3d_image, x=(0, MNI152_mask.shape[0]-1),y=(0, MNI152_mask.shape[1]-1),z=(0, MNI152_mask.shape[2]-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 109, 91)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROI_AAL = nb.load('ROI_MNI_V7.nii')\n",
    "ROI_AAL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn.masking\n",
    "masked_ROI_AAL = nilearn.masking.apply_mask(ROI_AAL, mask_img=MNI152_mask)\n",
    "np.save('masked_AAL_ROI.npy',masked_ROI_AAL[np.newaxis,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c720d9c74e93498a89c303f3dd0f1d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='x', max=90), IntSlider(value=54, description='y', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_3d_image(x, y, z)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import itk              # 2D 및 3D 이미지 시각화 라이브러리\n",
    "import itkwidgets\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "\n",
    "def explore_3d_image(x, y, z):\n",
    "    #plt.figure(figsize=(8,10))\n",
    "    # plt.title('Explore Layers of MRI', fontsize=18)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(8, 12))\n",
    "    \n",
    "    axes[0].imshow(MNI152_mask.get_fdata()[x, :, :], cmap='gray',alpha=0.4)\n",
    "    axes[0].imshow(ROI_AAL.get_fdata()[ x, :, :], cmap='gist_heat',alpha=0.7)\n",
    "    axes[1].imshow(MNI152_mask.get_fdata()[:, y, :], cmap='gray',alpha=0.4)\n",
    "    axes[1].imshow(ROI_AAL.get_fdata()[:, y, :], cmap='gist_heat',alpha=0.7)\n",
    "    axes[2].imshow(MNI152_mask.get_fdata()[:, :, z], cmap='gray',alpha=0.4)\n",
    "    axes[2].imshow(ROI_AAL.get_fdata()[ :, :, z], cmap='gist_heat',alpha=0.7)\n",
    "    \n",
    "    #plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #return layer\n",
    " \n",
    "# Run the ipywidgets interact() function to explore the data\n",
    "interact(explore_3d_image, x=(0, MNI152_mask.shape[0]-1),y=(0, MNI152_mask.shape[1]-1),z=(0, MNI152_mask.shape[2]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmap = nb.load('/global/cfs/cdirs/m4244/registration/20249_unzip_1_beta_MNI/1000254_20249_2_0/zstat1_MNI_space.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42947b06b11a42f8abfb3d8080b954fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=45, description='x', max=90), IntSlider(value=54, description='y', max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.explore_3d_image(x, y, z)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import itk              # 2D 및 3D 이미지 시각화 라이브러리\n",
    "import itkwidgets\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons\n",
    "\n",
    "def explore_3d_image(x, y, z):\n",
    "    #plt.figure(figsize=(8,10))\n",
    "    # plt.title('Explore Layers of MRI', fontsize=18)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(8, 12))\n",
    "    \n",
    "    axes[0].imshow(MNI152_mask.get_fdata()[x, :, :], cmap='gist_heat')\n",
    "    axes[0].imshow(tmap.get_fdata()[ x, :, :], cmap='gray',alpha=0.4)\n",
    "    axes[1].imshow(MNI152_mask.get_fdata()[:, y, :], cmap='gist_heat')\n",
    "    axes[1].imshow(tmap.get_fdata()[:, y, :], cmap='gray',alpha=0.4)\n",
    "    axes[2].imshow(MNI152_mask.get_fdata()[:, :, z], cmap='gist_heat')\n",
    "    axes[2].imshow(tmap.get_fdata()[ :, :, z], cmap='gray',alpha=0.4)\n",
    "    \n",
    "    #plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #return layer\n",
    " \n",
    "# Run the ipywidgets interact() function to explore the data\n",
    "interact(explore_3d_image, x=(0, MNI152_mask.shape[0]-1),y=(0, MNI152_mask.shape[1]-1),z=(0, MNI152_mask.shape[2]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DCNN",
   "language": "python",
   "name": "3dcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
